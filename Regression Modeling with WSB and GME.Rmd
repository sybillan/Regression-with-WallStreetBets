---
title: "GME Regression Model"
output: github_document
editor_options: 
  chunk_output_type: inline
---


## Initial Setup
```{r setup, include=TRUE, message=FALSE,warning=FALSE}

#Using Statlearning to draw regression model of how the users of subreddit WallStreetBets drove price of GME in 2021

#Initial Setup

library(dplyr) # for filter and join 
library(readr) # for read_csv
library(tidyverse) #for str_which
library(ggplot2) #for ggplot

#Loading WallStreetBets file
dataset1 <- read_csv("reddit_wsb.csv",col_types = cols(.default = "c"))
head(dataset1)

#Loading GME Market data from Jan to April 2021
GME<-read.table(unz("archive.zip","GME.csv"), header=T,quote="\"",sep=",")
head(GME)
```

WSB data for feature 'title' has punctuation in text including ",", ";", ".", "/", "", and also, notoriously, the csv delimiter "\|". Using gsub for eliminating delimiters from the title. Thanks to [MLane\@Kaggle] for providing the Data Cleaning algorithm for WallStreetBets. 

```{r clean, include=TRUE, message=FALSE,warning=FALSE}
dataset1$title = gsub(pattern = "\\,",".",dataset1$title)
dataset1$body  = gsub(pattern = "\\,",".",dataset1$body)
wsb<-dataset1

```

# I. Linear Regression Fit -- GME High Price Against Freq of daily posts that mention 'GME' or 'GameStop'

```{r,echo=TRUE}
#Formatting Dates on both GME and WSB file
GME$Date<-as.Date(GME$Date,"%Y-%m-%d")  
wsb$X<-as.Date(wsb$timestamp,"%m/%d/%Y")

#Filter for keywords 'GameStop' and 'GME' using index
m<-str_which(wsb$title,"GME")
m<-append(m,str_which(wsb$title,"GameStop"))
wsb_gamestop<-wsb[c(m),]

#Deriving the frequency table for GameStop/GME Mentions in subreddit against Date
freq<-data.frame(table(wsb_gamestop$X))
freq$Var1<-as.Date(freq$Var1,"%Y-%m-%d")
colnames(freq)<-c("Date","Freq")

#Performing Left Join with the GME Stock Index file via Date
GME<-dplyr::left_join(GME,freq,by="Date")

GME$Freq[is.na(GME$Freq)] <- 0

#Regression modeling of GME High Price against Freq of GME mentions on WallStreetBets 
reg<-lm(High~Freq,data=GME)
summary(reg)

plot(GME$Freq, GME$High)

abline(lm(High~Freq,data=GME))


```

The abline is the least squares line and is determined by the coefficient estimates  β0 ~ 143.5 (intercept) and β1~ 0.097 (slope). F statistic >1 and R squared value 0.1135 measures order of variance between Daily Volume of GME mentions on WallStreetBets and GME'S Daily High Price. Null hypothesis can be rejected, since p is significant at 0.00162. So, we reject the null hypothesis and deem there to be a meaningful relationship between predictor and dependent variable.
```{r,echo=TRUE}

#Running Regression Diagnostics
par(mfrow=c(2,2))
plot(reg)

```



# II. Running Regression Diagnostics

Residuals vs Fitted. Used to check the linear relationship assumptions. A horizontal line, without distinct patterns is an indication for a linear relationship, what is good.

Normal Q-Q. Used to examine whether the residuals are normally distributed. It’s good if residuals points follow the straight dashed line.

Scale-Location (or Spread-Location). Used to check the homogeneity of variance of the residuals (homoscedasticity). Horizontal line with equally spread points is a good indication of homoscedasticity.

Residuals vs Leverage. Used to identify influential cases, that is extreme values that might influence the regression results when included or excluded from the analysis. 

Looking at the Residuals vs Leverage plot, we look for data points outside of a dashed line, Cook’s distance. When the points are outside, this means that they have high Cook’s distance scores. In such a case, the values are influential and have a bearing on the regression results. The regression results will be altered if we exclude those cases i.e. #17,#18,#19.

Looking at our outliers

```{r}
GME[c(17,18,19),]

  
  ggplot(GME, aes(Date,High)) + 
  geom_line(colour="blue") + scale_x_date(date_labels = "%b %d", breaks= "9 days")

     
```

Since the outliers pertain to the critical price movement dates,  we are retaining them for the purpose of this analysis.

# III. Multiple Regression Fit-- High Price Against Musk's tweet that mentions GME/GameStop 'Gamestonk!!' and Freq of GME mention on Subreddit WallStreetBets

```{r}
#Assessing Impact of Musk's solitary tweet on 26th Jan on GME Price Movement
GME$Musk<-0
GME$Musk[GME$Date=="2021-01-26"]<-1

summary(lm(High~Freq+Musk,data=GME))
```

There is no relationship to be inferred between GME's Stock High Price and Musk's tweet. As observed, p=0.94173 is not significant and Residual Standard Error is high at 89.57.

```{r,echo=TRUE}
GME$Change<-((GME$Close-GME$Open)/GME$Open)*100
summary(lm(Change~Freq+Musk,data=GME))

plot(GME$Musk,GME$Change)
abline(lm(Change~Musk,data=GME))

```

# IV. Multiple Regression Fit-- Change in Price Against Musk's tweet that mentions GME/GameStop 'Gamestonk'and Freq of GME mention on Subreddit WallStreetBets

```{r,echo=TRUE}
GME$Musk<-0
GME$Musk[GME$Date=="2021-01-26"]<-1

summary(lm(High~Freq+Musk,data=GME))
GME$Change<-((GME$Close-GME$Open)/GME$Open)*100

summary(lm(Change~Freq+Musk,data=GME))

plot(GME$Musk,GME$Change)
abline(lm(Change~Musk,data=GME))
```

While GME's High Price is not responsive to Musk's tweeting, the % change in price is, with p-value at 0.000882 and also observable using correlation function. % Change in Stock Price is positively correlated with Musk's tweeting with F-Statistic being 6.948 and >1. 

```{r,echo=TRUE}
correlation_matrix<-cor(GME[,-1])
correlation_matrix
```
